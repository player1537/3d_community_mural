==================
3D Community Mural
==================

This project includes the server side component to the 3D Community
Mural project. The 3D aspects come from the use of OSPRay on the
server side, following a Tapestry-like architecture.


How to Run
----------

Before you run these commands, you need to have OSPRay downloaded. You
can download it from its Releases page on GitHub [0]. We are using
version 1.8.5.

To run the server, we need to create a Docker image with OSPRay
installed. You can do this by first running:

  $ ./go.sh build

Then to actually run the server:

  $ ./go.sh run python3.7 -u server.py /opt/app/server

Then open http://localhost:8801 and you will see the scene
rendered. You can click and drag on the image that's returned to
rotate around the scene. Zooming does not currently work well.

[0]: https://github.com/ospray/ospray/releases


Using the Service
-----------------

This service is best described as a web-accessible rendering service
that can be used entirely from requesting special URLs and getting
images (JPEGs) back. This means that after constructing a URL you
can use it in an HTML image tag.

The Seelab team will handle running the service until the MVP is
finished, after which point, we will hand off a Docker image that
can be run on production systems. The Seelab base URL is:

  http://accona.eecs.utk.edu:8801/

The service is entirely stateless, so it will not remember anything
between requests. This means that everything it needs to know to
render the scene will have to be passed every request. This means we
will need to know the camera position, camera view direction, camera
up direction, desired resolution, and any scene information. For
the community mural, most of these parameters can be fixed, which
simplifies the requests.

Here is a pair of JavaScript functions. The first one requires all
information in the Tapestry URLs. The second one has a simplified
interface that only needs the camera horizontal/vertical positions,
image resolution, and ball position.

function makeTapestryURL(options) {
	const O = options;
	
	const parts = [
		O.prefix,  // base URL
		'image',
		O.scene,
		O.px, O.py, O.pz,  // position
		O.ux, O.uy, O.uz,  // up
		O.vx, O.vy, O.vz,  // view
		O.quality,  // resolution (square image)
		O.extra,  // extra parameters, like tiling
	];
	
	return parts.join('/');
}

function makeMuralURL(options) {
	const O = options;
	
	const sceneParts = [
		'scene',
		'ball',
		O.bx, O.by, O.bz,  // ball position
	];
	
	return makeTapestryURL({
		prefix: 'http://accona.eecs.utk.edu:8801',
		scene: sceneParts.join(','),
		px: O.cameraHorizontal,  // camera x
		py: O.cameraVertical,  // camera y
		pz: -2.0,  // camera depth
		ux: 0, uy: 1, uz: 0,
		vx: 0, vy: 0, vz: 1,
		quality: O.quality,
		extra: '',
	});
}

For example, you could use this to construct a render looking directly
at a ball, that is directly in the center of the scene.

const url = makeMuralURL({
	bx: 0.0, by: 0.0, bz: 0.5,
	cameraHorizontal: 0.0,
	cameraVertical: 0.0,
	quality: 512,
});

This results in:

  http://accona.eecs.utk.edu:8801/image/scene,ball,0.5,0.1,0.5/0/0/-2/0/1/0/0/0/1/512/

Likewise, we could make the ball move around in a circle in the
viewport:

for (let i=0; i<100; ++i) {
	const url = makeMuralURL({
		bx: Math.cos(2 * Math.PI * i / 100),
		by: Math.sin(2 * Math.PI * i / 100),
		bz: 0.5,
		cameraHorizontal: 0.0,
		cameraVertical: 0.0,
		quality: 512,
	});
	
	// set an <img> tag's src to this url
}

The scene has a fixed size and has limits on X, Y, and Z. Anything
(camera or ball) can be put anywhere in this fixed space, but going
outside of it (e.g. X=3.5) will not work as expected.

  X: -1 (left) to +1 (right)
  Y: -1 (bottom) to +1 (top)
  Z: 0 (camera plane) to +1 (far end of the box)


Using OBJ Models
----------------

OSPRay natively supports triangle meshes. However, parsing OBJ files in
C isn't the most straightforward thing, and it adds to the processing
time. Instead, it is easier to make use of a preprocessing step to
convert the OBJ file into a raw binary file.

The mechanism to do this is in the obj_to_bin.py script, which uses
PyWavefront to parse the OBJ and MTL files.

The binary format is unique but simple:

  <header> := <u8 has_vertex> <u8 has_index> <u8 has_extra1> <u8 has_extra2>
  <vertex> := <i32 nvertex> { <f32 x> <f32 y> <f32 z> } ... (nvertex times)
  <index> := <i32 nindex> { <i32 i> <i32 j> <i32 k> } ... (nindex times)
  <extra1> := (unused)
  <extra2> := (unused)
  <data> := <header> \
            ( <vertex> if has_vertex ) \
            ( <index> if has_index ) \
            ( <extra1> if has_extra1 ) \
            ( <extra2> if has_extra2 )

has_vertex is either 'V' or '<spc>'. has_index is either 'I' or
'<spc>'. has_extra1 and has_extra2 aren't defined yet, so they are
currently both '<spc>'.

A Makefile exists to help convert the models more easily. To run it,
make sure all the models (and their MTL files) are in the models/
directory, then just run make to convert them all.

  $ tree models/
  models/
  ├── Donut2.mtl
  ├── Donut2.obj
  ├── Platonic2.mtl
  └── Platonic2.obj
  
  0 directories, 4 files
  $ make
  ./go.sh python obj_to_bin.py --output gen/Platonic2.bin models/Platonic2.obj
  ./go.sh python obj_to_bin.py --output gen/Donut2.bin models/Donut2.obj --rescale
  $ tree gen
  gen
  ├── Donut2.bin
  └── Platonic2.bin
  
  0 directories, 2 files

Inside the Makefile, you can specify if you want the model
rescaled. This will make it fit within a -1 to 1 sized box (keeping
aspect ratio). To enable it for a model (like Donut2), you would add
a line to the Makefile like:

  gen/Donut2.bin: rescale := --rescale

And the next time you build Donut2.bin, it will be rescaled correctly.
